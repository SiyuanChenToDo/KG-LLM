#!/usr/bin/env python3
"""
èŠ‚ç‚¹å±æ€§æŸ¥è¯¢API - å®ç”¨æŒ‡å—
========================

è¿™ä¸ªæ–‡ä»¶å±•ç¤ºäº†åœ¨å„ç§ç¯å¢ƒä¸­å¦‚ä½•è·å–èŠ‚ç‚¹å±æ€§çš„æœ€ä½³å®è·µ

ä½¿ç”¨åœºæ™¯ï¼š
1. ğŸ“ ç›´æ¥ä»JSONæ–‡ä»¶æŸ¥è¯¢ (æœ€å¿«é€Ÿ)
2. ğŸ” åœ¨LightRAGç¯å¢ƒä¸­æŸ¥è¯¢ (æœ€å®Œæ•´)
3. ğŸ¯ ç‰¹å®šèŠ‚ç‚¹æŸ¥è¯¢ (æœ€çµæ´»)
"""

import json
import os

# æ™ºèƒ½è·¯å¾„æ£€æµ‹ - æ”¯æŒä»ä¸åŒç›®å½•è°ƒç”¨
def get_kg_file_path():
    """
    è·å–çŸ¥è¯†å›¾è°±æ–‡ä»¶è·¯å¾„ï¼ŒæŒ‰ä¼˜å…ˆçº§å°è¯•å¤šä¸ªå¯èƒ½çš„ä½ç½®
    """
    possible_paths = [
        "/root/autodl-tmp/LightRAG/data/final_custom_kg_papers.json",
        "/root/autodl-tmp/LightRAG/data/test_custom_kg_papers.json",
        "data/final_custom_kg_papers.json",
        "data/custom_kg_papers.json", 
        "data/test_custom_kg_papers.json",
        "data/custom_kg_fixed.json",
        "data/custom_kg.json",
        "../data/final_custom_kg_papers.json",
        "../data/custom_kg_papers.json", 
        "../data/test_custom_kg_papers.json",
        "../data/custom_kg_fixed.json",
        "../data/custom_kg.json",
        "../../data/final_custom_kg_papers.json",
        "../../data/custom_kg_papers.json", 
        "../../data/test_custom_kg_papers.json",
        "../../data/custom_kg_fixed.json",
        "../../data/custom_kg.json"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            return path
    
    # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼ŒæŠ›å‡ºå¼‚å¸¸å¹¶æ˜¾ç¤ºå°è¯•è¿‡çš„è·¯å¾„
    raise FileNotFoundError(f"çŸ¥è¯†å›¾è°±æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œå°è¯•è¿‡çš„è·¯å¾„: {possible_paths}")

# ========================
# æ–¹æ³•1: ç›´æ¥ä»JSONæ–‡ä»¶æŸ¥è¯¢ (æ¨è)
# ========================

def get_paper_attributes(paper_index=0):
    """
    è·å–æŒ‡å®špaperèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    
    Args:
        paper_index (int): paperèŠ‚ç‚¹çš„ç´¢å¼• (é»˜è®¤0ï¼Œå³ç¬¬ä¸€ç¯‡è®ºæ–‡)
        
    Returns:
        dict: paperèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    papers = [e for e in kg_data["entities"] if e["entity_type"] == "paper"]
    
    if paper_index < len(papers):
        return papers[paper_index]
    return None

def get_research_question_attributes(rq_index=0):
    """
    è·å–æŒ‡å®šresearch_questionèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    
    Args:
        rq_index (int): research_questionèŠ‚ç‚¹çš„ç´¢å¼•
        
    Returns:
        dict: research_questionèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    rqs = [e for e in kg_data["entities"] if e["entity_type"] == "research_question"]
    
    if rq_index < len(rqs):
        return rqs[rq_index]
    return None

def get_solution_attributes(sol_index=0):
    """
    è·å–æŒ‡å®šsolutionèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    
    Args:
        sol_index (int): solutionèŠ‚ç‚¹çš„ç´¢å¼•
        
    Returns:
        dict: solutionèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    solutions = [e for e in kg_data["entities"] if e["entity_type"] == "solution"]
    
    if sol_index < len(solutions):
        return solutions[sol_index]
    return None

def find_paper_by_title(title_keyword):
    """
    æ ¹æ®æ ‡é¢˜å…³é”®è¯æŸ¥æ‰¾è®ºæ–‡
    
    Args:
        title_keyword (str): æ ‡é¢˜ä¸­çš„å…³é”®è¯
        
    Returns:
        list: åŒ¹é…çš„paperèŠ‚ç‚¹åˆ—è¡¨
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    papers = [e for e in kg_data["entities"] if e["entity_type"] == "paper"]
    
    matching_papers = []
    for paper in papers:
        if title_keyword.lower() in paper.get("title", "").lower():
            matching_papers.append(paper)
    
    return matching_papers

def get_paper_research_questions(paper_entity_name):
    """
    è·å–æŒ‡å®šè®ºæ–‡çš„æ‰€æœ‰ç ”ç©¶é—®é¢˜
    
    Args:
        paper_entity_name (str): paperèŠ‚ç‚¹çš„entity_name
        
    Returns:
        list: è¯¥è®ºæ–‡çš„æ‰€æœ‰research_questionèŠ‚ç‚¹
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    # æ‰¾åˆ°å±äºè¯¥è®ºæ–‡çš„ç ”ç©¶é—®é¢˜
    rqs = []
    for entity in kg_data["entities"]:
        if (entity["entity_type"] == "research_question" and 
            entity["entity_name"].startswith(paper_entity_name + "_RQ_")):
            rqs.append(entity)
    
    return rqs

def get_research_question_solutions(rq_entity_name):
    """
    è·å–æŒ‡å®šç ”ç©¶é—®é¢˜çš„æ‰€æœ‰è§£å†³æ–¹æ¡ˆ
    
    Args:
        rq_entity_name (str): research_questionèŠ‚ç‚¹çš„entity_name
        
    Returns:
        list: è¯¥ç ”ç©¶é—®é¢˜çš„æ‰€æœ‰solutionèŠ‚ç‚¹
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    # ä»research_questionçš„entity_nameæ¨å¯¼å¯¹åº”çš„solution
    # ä¾‹å¦‚: Paper_RQ_1 -> Paper_SOL_1
    base_name = rq_entity_name.replace("_RQ_", "_SOL_")
    if base_name.endswith("_RQ_"):
        base_name = base_name[:-4] + "_SOL_"
    
    solutions = []
    for entity in kg_data["entities"]:
        if (entity["entity_type"] == "solution" and 
            entity["entity_name"].startswith(base_name)):
            solutions.append(entity)
    
    return solutions

def get_solution_attributes_by_name(entity_name):
    """
    æ ¹æ®å®ä½“åç§°è·å–solutionèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    
    Args:
        entity_name (str): solutionèŠ‚ç‚¹çš„entity_name
        
    Returns:
        dict: solutionèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    solutions = [e for e in kg_data["entities"] if e["entity_type"] == "solution"]
    
    for solution in solutions:
        if solution.get("entity_name") == entity_name:
            return solution
    
    return None

def get_paper_attributes_by_name(entity_name):
    """
    æ ¹æ®å®ä½“åç§°è·å–paperèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    
    Args:
        entity_name (str): paperèŠ‚ç‚¹çš„entity_name
        
    Returns:
        dict: paperèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    papers = [e for e in kg_data["entities"] if e["entity_type"] == "paper"]
    
    for paper in papers:
        if paper.get("entity_name") == entity_name:
            return paper
    
    return None

def get_research_question_attributes_by_name(entity_name):
    """
    æ ¹æ®å®ä½“åç§°è·å–research_questionèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
    
    Args:
        entity_name (str): research_questionèŠ‚ç‚¹çš„entity_name
        
    Returns:
        dict: research_questionèŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§ï¼Œå¦‚æœæœªæ‰¾åˆ°åˆ™è¿”å›None
    """
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    
    rqs = [e for e in kg_data["entities"] if e["entity_type"] == "research_question"]
    
    for rq in rqs:
        if rq.get("entity_name") == entity_name:
            return rq
    
    return None

# ========================
# æ–¹æ³•2: åœ¨LightRAGä¸­æŸ¥è¯¢èŠ‚ç‚¹å±æ€§çš„ä»£ç ç‰‡æ®µ
# ========================

# åœ¨lightrag_ollama_demo.pyä¸­æ·»åŠ è¿™æ®µä»£ç æ¥æŸ¥è¯¢èŠ‚ç‚¹å±æ€§ï¼š
"""
async def query_node_attributes_in_lightrag(rag):
    '''åœ¨LightRAGç¯å¢ƒä¸­æŸ¥è¯¢èŠ‚ç‚¹å±æ€§'''
    
    # è·å–å›¾å­˜å‚¨å®ä¾‹
    graph = rag.chunk_entity_relation_graph
    
    # è·å–æ‰€æœ‰èŠ‚ç‚¹æ ‡ç­¾
    all_labels = await graph.get_all_labels()
    print(f"æ€»èŠ‚ç‚¹æ•°: {len(all_labels)}")
    
    # æŒ‰ç±»å‹åˆ†ç±»èŠ‚ç‚¹
    papers = []
    research_questions = []
    solutions = []
    
    for label in all_labels:
        node_data = await graph.get_node(label)
        if node_data:
            entity_type = node_data.get("entity_type", "unknown")
            if entity_type == "paper":
                papers.append((label, node_data))
            elif entity_type == "research_question":
                research_questions.append((label, node_data))
            elif entity_type == "solution":
                solutions.append((label, node_data))
    
    # æ˜¾ç¤ºç¬¬ä¸€ç¯‡è®ºæ–‡çš„å±æ€§
    if papers:
        label, attributes = papers[0]
        print(f"PaperèŠ‚ç‚¹: {label}")
        for key, value in attributes.items():
            print(f"  {key}: {value}")
        
        # è·å–è¯¥è®ºæ–‡çš„å…³ç³»
        edges = await graph.get_node_edges(label)
        print(f"å…³è”å…³ç³»æ•°: {len(edges)}")
        
        for src, tgt in edges:
            edge_data = await graph.get_edge(src, tgt)
            if edge_data:
                print(f"  å…³ç³»: {src} -> {tgt}")
                print(f"    å±æ€§: {edge_data}")
    
    return papers, research_questions, solutions
"""

# ========================
# å®ç”¨å·¥å…·å‡½æ•°
# ========================

def print_node_attributes(node, node_type="Node"):
    """
    ç¾è§‚åœ°æ‰“å°èŠ‚ç‚¹å±æ€§
    
    Args:
        node (dict): èŠ‚ç‚¹æ•°æ®
        node_type (str): èŠ‚ç‚¹ç±»å‹åç§°
    """
    if not node:
        print("âŒ èŠ‚ç‚¹ä¸å­˜åœ¨")
        return
    
    print(f"\nğŸ“‹ {node_type}èŠ‚ç‚¹å±æ€§:")
    print("=" * 50)
    
    # å®šä¹‰å„ç±»å‹èŠ‚ç‚¹çš„é‡è¦å±æ€§
    important_attrs = {
        "paper": ["entity_name", "title", "authors", "year", "conference", "abstract"],
        "research_question": ["entity_name", "research_question", "simplified_research_question"],
        "solution": ["entity_name", "solution", "simplified_solution"]
    }
    
    node_type_key = node.get("entity_type", "").lower()
    if node_type_key in important_attrs:
        # å…ˆæ˜¾ç¤ºé‡è¦å±æ€§
        for attr in important_attrs[node_type_key]:
            if attr in node:
                value = node[attr]
                if isinstance(value, str) and len(value) > 100:
                    print(f"ğŸ”¹ {attr}: {value[:80]}...")
                else:
                    print(f"ğŸ”¹ {attr}: {value}")
        
        print("\nğŸ“ å…¶ä»–å±æ€§:")
        # å†æ˜¾ç¤ºå…¶ä»–å±æ€§
        for key, value in node.items():
            if key not in important_attrs[node_type_key]:
                if isinstance(value, str) and len(value) > 100:
                    print(f"   {key}: {value[:80]}...")
                else:
                    print(f"   {key}: {value}")
    else:
        # æ˜¾ç¤ºæ‰€æœ‰å±æ€§
        for key, value in node.items():
            if isinstance(value, str) and len(value) > 100:
                print(f"ğŸ”¹ {key}: {value[:80]}...")
            else:
                print(f"ğŸ”¹ {key}: {value}")

# ========================
# ä½¿ç”¨ç¤ºä¾‹
# ========================

if __name__ == "__main__":
    print("ğŸš€ èŠ‚ç‚¹å±æ€§æŸ¥è¯¢API - ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # ç¤ºä¾‹1: è·å–ç¬¬ä¸€ç¯‡è®ºæ–‡çš„å±æ€§
    print("\nğŸ“„ ç¤ºä¾‹1: è·å–ç¬¬ä¸€ç¯‡è®ºæ–‡çš„å±æ€§")
    paper = get_paper_attributes(0)
    print_node_attributes(paper, "Paper")
    
    # ç¤ºä¾‹2: æ ¹æ®å…³é”®è¯æŸ¥æ‰¾è®ºæ–‡
    print("\nğŸ” ç¤ºä¾‹2: æ ¹æ®å…³é”®è¯æŸ¥æ‰¾è®ºæ–‡")
    papers = find_paper_by_title("Attention")
    print(f"æ‰¾åˆ° {len(papers)} ç¯‡åŒ…å«'Attention'çš„è®ºæ–‡:")
    for i, paper in enumerate(papers, 1):
        print(f"  {i}. {paper['title']}")
    
    # ç¤ºä¾‹3: è·å–ç¬¬ä¸€ç¯‡è®ºæ–‡çš„ç ”ç©¶é—®é¢˜
    if papers:
        print(f"\nâ“ ç¤ºä¾‹3: è·å–ç¬¬ä¸€ç¯‡è®ºæ–‡çš„ç ”ç©¶é—®é¢˜")
        rqs = get_paper_research_questions(papers[0]["entity_name"])
        print(f"è¯¥è®ºæ–‡æœ‰ {len(rqs)} ä¸ªç ”ç©¶é—®é¢˜:")
        for i, rq in enumerate(rqs, 1):
            print(f"  {i}. {rq.get('simplified_research_question', 'N/A')}")
    
    # ç¤ºä¾‹4: è·å–ç¬¬ä¸€ä¸ªç ”ç©¶é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ
    if rqs:
        print(f"\nğŸ’¡ ç¤ºä¾‹4: è·å–ç¬¬ä¸€ä¸ªç ”ç©¶é—®é¢˜çš„è§£å†³æ–¹æ¡ˆ")
        solutions = get_research_question_solutions(rqs[0]["entity_name"])
        print(f"è¯¥ç ”ç©¶é—®é¢˜æœ‰ {len(solutions)} ä¸ªè§£å†³æ–¹æ¡ˆ:")
        for i, sol in enumerate(solutions, 1):
            print(f"  {i}. {sol.get('simplified_solution', 'N/A')}")
    
    print(f"\nâœ… APIä½¿ç”¨ç¤ºä¾‹å®Œæˆ!")
    print(f"ğŸ’¡ æ‚¨å¯ä»¥åœ¨è‡ªå·±çš„ä»£ç ä¸­å¯¼å…¥è¿™äº›å‡½æ•°æ¥æŸ¥è¯¢èŠ‚ç‚¹å±æ€§")

def get_all_papers():
    """è·å–æ‰€æœ‰è®ºæ–‡èŠ‚ç‚¹"""
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    return [e for e in kg_data["entities"] if e["entity_type"] == "paper"]

def get_all_research_questions():
    """è·å–æ‰€æœ‰ç ”ç©¶é—®é¢˜èŠ‚ç‚¹"""
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    return [e for e in kg_data["entities"] if e["entity_type"] == "research_question"]

def get_all_solutions():
    """è·å–æ‰€æœ‰è§£å†³æ–¹æ¡ˆèŠ‚ç‚¹"""
    kg_file_path = get_kg_file_path()
    with open(kg_file_path, 'r', encoding='utf-8') as f:
        kg_data = json.load(f)
    return [e for e in kg_data["entities"] if e["entity_type"] == "solution"]
